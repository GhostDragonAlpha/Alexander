#!/usr/bin/env python3
"""
Automated Test Dashboard Generator for Alexander

Generates interactive HTML dashboards from test results
Zero human effort - fully automated report generation

Features:
- Interactive charts (FPS history, memory usage, pass rates)
- Station breakdown with drill-down
- Performance trends
- Human review queue
- Mobile-friendly responsive design
- Auto-refreshing (when deployed on web server)

Usage:
    python generate_dashboard.py --input TestResults --output test_dashboard.html
    python generate_dashboard.py --input TestResults --output dashboard.html --auto-refresh 60
"""

import argparse
import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import statistics


class DashboardGenerator:
    """Generate interactive HTML dashboard from test results"""

    def __init__(self, results_dir: Path):
        self.results_dir = Path(results_dir)
        self.test_results = self.load_latest_results()
        self.historical_results = self.load_historical_results()

    def load_latest_results(self) -> Dict:
        """Load most recent test results"""
        result_files = sorted(self.results_dir.glob("TestResults_*.json"))
        if not result_files:
            return {}

        with open(result_files[-1]) as f:
            return json.load(f)

    def load_historical_results(self, limit: int = 30) -> List[Dict]:
        """Load historical results for trend analysis"""
        result_files = sorted(self.results_dir.glob("TestResults_*.json"))
        historical = []

        for result_file in result_files[-limit:]:
            try:
                with open(result_file) as f:
                    data = json.load(f)
                    historical.append(data)
            except:
                continue

        return historical

    def generate_html(self, output_file: Path, auto_refresh: int = 0):
        """Generate complete HTML dashboard"""

        if not self.test_results:
            print("No test results found!")
            return

        html = self._generate_html_structure(auto_refresh)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html)

        print(f"Dashboard generated: {output_file}")
        print(f"Open in browser: file://{output_file.absolute()}")

    def _generate_html_structure(self, auto_refresh: int) -> str:
        """Generate HTML structure"""

        stats = self._calculate_statistics()
        trends = self._calculate_trends()
        human_review_items = self._get_human_review_items()

        refresh_meta = f'<meta http-equiv="refresh" content="{auto_refresh}">' if auto_refresh > 0 else ''

        return f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alexander - Test Dashboard</title>
    {refresh_meta}
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
    <style>
        {self._get_css()}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ðŸš€ Alexander Comprehensive Test Dashboard</h1>
            <p class="timestamp">Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            {f'<p class="auto-refresh">Auto-refresh: {auto_refresh}s</p>' if auto_refresh > 0 else ''}
        </header>

        {self._generate_alert_banner(stats)}

        <div class="metrics-grid">
            {self._generate_metric_card('Overall Pass Rate', f"{stats['pass_rate']:.1f}%",
                                       self._get_status_class(stats['pass_rate'], 95, 85))}
            {self._generate_metric_card('Total Tests', str(stats['total_tests']), 'neutral')}
            {self._generate_metric_card('Passed', str(stats['passed']), 'pass')}
            {self._generate_metric_card('Failed', str(stats['failed']),
                                       'fail' if stats['failed'] > 0 else 'neutral')}
            {self._generate_metric_card('Average FPS', f"{stats.get('avg_fps', 0):.1f}",
                                       self._get_fps_status(stats.get('avg_fps', 0)))}
            {self._generate_metric_card('Memory Usage', f"{stats.get('avg_memory_mb', 0):.0f} MB",
                                       self._get_memory_status(stats.get('avg_memory_mb', 0)))}
        </div>

        {self._generate_charts_section(trends)}

        {self._generate_station_breakdown()}

        {self._generate_human_review_section(human_review_items)}

        {self._generate_performance_details()}

        <footer>
            <p>Automated dashboard generated by Alexander Test System</p>
            <p>For issues, check: <code>TestResults/</code> directory</p>
        </footer>
    </div>

    <script>
        {self._generate_javascript(trends)}
    </script>
</body>
</html>"""

    def _get_css(self) -> str:
        """Get CSS styles"""
        return """
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%);
            color: #e0e0e0;
            padding: 20px;
            line-height: 1.6;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            padding: 30px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            backdrop-filter: blur(10px);
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .timestamp, .auto-refresh {
            color: #999;
            font-size: 0.9em;
        }

        .alert-banner {
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 30px;
            font-weight: bold;
            text-align: center;
        }

        .alert-success {
            background: #4caf50;
            color: white;
        }

        .alert-warning {
            background: #ff9800;
            color: white;
        }

        .alert-danger {
            background: #f44336;
            color: white;
        }

        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 40px;
        }

        .metric-card {
            background: rgba(255, 255, 255, 0.05);
            padding: 25px;
            border-radius: 12px;
            text-align: center;
            border: 2px solid transparent;
            transition: all 0.3s;
        }

        .metric-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }

        .metric-card.pass {
            border-color: #4caf50;
        }

        .metric-card.fail {
            border-color: #f44336;
        }

        .metric-card.warning {
            border-color: #ff9800;
        }

        .metric-label {
            font-size: 0.9em;
            color: #999;
            margin-bottom: 10px;
        }

        .metric-value {
            font-size: 2.5em;
            font-weight: bold;
        }

        .metric-card.pass .metric-value {
            color: #4caf50;
        }

        .metric-card.fail .metric-value {
            color: #f44336;
        }

        .metric-card.warning .metric-value {
            color: #ff9800;
        }

        .section {
            background: rgba(255, 255, 255, 0.05);
            padding: 30px;
            border-radius: 12px;
            margin-bottom: 30px;
        }

        h2 {
            margin-bottom: 20px;
            font-size: 1.8em;
            color: #667eea;
        }

        .chart-container {
            position: relative;
            height: 300px;
            margin: 20px 0;
        }

        .station-list {
            display: grid;
            gap: 15px;
        }

        .station-item {
            background: rgba(255, 255, 255, 0.03);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }

        .station-item.failed {
            border-left-color: #f44336;
        }

        .station-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }

        .station-name {
            font-size: 1.2em;
            font-weight: bold;
        }

        .station-stats {
            display: flex;
            gap: 15px;
            font-size: 0.9em;
        }

        .pass-count {
            color: #4caf50;
        }

        .fail-count {
            color: #f44336;
        }

        .review-item {
            background: rgba(255, 152, 0, 0.1);
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #ff9800;
            margin-bottom: 10px;
        }

        .review-item h4 {
            color: #ff9800;
            margin-bottom: 5px;
        }

        footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px;
            color: #666;
            font-size: 0.9em;
        }

        code {
            background: rgba(255, 255, 255, 0.1);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 1.8em;
            }

            .metrics-grid {
                grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            }

            .metric-value {
                font-size: 2em;
            }
        }
        """

    def _calculate_statistics(self) -> Dict:
        """Calculate overall statistics"""
        if not self.test_results:
            return {}

        stats = {
            'total_tests': self.test_results.get('totalTests', 0),
            'passed': self.test_results.get('passedTests', 0),
            'failed': self.test_results.get('failedTests', 0),
            'pass_rate': self.test_results.get('passRate', 0),
        }

        # Calculate average FPS and memory from stations
        stations = self.test_results.get('stations', [])
        fps_values = []
        memory_values = []

        for station in stations:
            perf = station.get('performanceMetrics', {})
            if 'averageFPS' in perf:
                fps_values.append(perf['averageFPS'])
            if 'memoryUsageMB' in perf:
                memory_values.append(perf['memoryUsageMB'])

        if fps_values:
            stats['avg_fps'] = statistics.mean(fps_values)
            stats['min_fps'] = min(fps_values)
            stats['max_fps'] = max(fps_values)

        if memory_values:
            stats['avg_memory_mb'] = statistics.mean(memory_values)

        return stats

    def _calculate_trends(self) -> Dict:
        """Calculate trends from historical data"""
        if len(self.historical_results) < 2:
            return {}

        trends = {
            'timestamps': [],
            'pass_rates': [],
            'fps_values': [],
            'memory_values': []
        }

        for result in self.historical_results:
            # Extract timestamp from filename or use current time
            trends['timestamps'].append(result.get('testRunStartTime', ''))
            trends['pass_rates'].append(result.get('passRate', 0))

            # Calculate averages
            stations = result.get('stations', [])
            fps_vals = [s.get('performanceMetrics', {}).get('averageFPS', 0)
                       for s in stations if 'performanceMetrics' in s]
            if fps_vals:
                trends['fps_values'].append(statistics.mean(fps_vals))

            mem_vals = [s.get('performanceMetrics', {}).get('memoryUsageMB', 0)
                       for s in stations if 'performanceMetrics' in s]
            if mem_vals:
                trends['memory_values'].append(statistics.mean(mem_vals))

        return trends

    def _get_human_review_items(self) -> List[Dict]:
        """Get items requiring human review"""
        review_items = []

        stations = self.test_results.get('stations', [])
        for station in stations:
            failed_tests = [t for t in station.get('testCases', [])
                          if t.get('status') in ['Failed', 'Timeout']]

            for test in failed_tests:
                review_items.append({
                    'station': station.get('name', 'Unknown'),
                    'test': test.get('testName', 'Unknown'),
                    'error': test.get('errorMessage', 'No details'),
                    'severity': test.get('severity', 'Error')
                })

        return review_items

    def _generate_metric_card(self, label: str, value: str, status: str) -> str:
        """Generate a metric card"""
        return f"""
            <div class="metric-card {status}">
                <div class="metric-label">{label}</div>
                <div class="metric-value">{value}</div>
            </div>
        """

    def _generate_alert_banner(self, stats: Dict) -> str:
        """Generate alert banner"""
        pass_rate = stats.get('pass_rate', 0)

        if pass_rate >= 95:
            return '<div class="alert-banner alert-success">âœ“ All Systems Nominal - No Human Review Required</div>'
        elif pass_rate >= 80:
            return '<div class="alert-banner alert-warning">âš  Some Tests Failed - Review Recommended</div>'
        else:
            return '<div class="alert-banner alert-danger">âœ— Critical Failures - Immediate Review Required</div>'

    def _generate_charts_section(self, trends: Dict) -> str:
        """Generate charts section"""
        return f"""
        <div class="section">
            <h2>ðŸ“Š Performance Trends</h2>
            <div class="chart-container">
                <canvas id="passRateChart"></canvas>
            </div>
            <div class="chart-container">
                <canvas id="fpsChart"></canvas>
            </div>
            <div class="chart-container">
                <canvas id="memoryChart"></canvas>
            </div>
        </div>
        """

    def _generate_station_breakdown(self) -> str:
        """Generate station breakdown section"""
        stations = self.test_results.get('stations', [])

        html = '<div class="section"><h2>ðŸŽ¯ Test Station Breakdown</h2><div class="station-list">'

        for station in stations:
            name = station.get('name', 'Unknown')
            total = len(station.get('testCases', []))
            passed = sum(1 for t in station.get('testCases', []) if t.get('status') == 'Passed')
            failed = sum(1 for t in station.get('testCases', []) if t.get('status') in ['Failed', 'Timeout'])

            failed_class = 'failed' if failed > 0 else ''

            html += f"""
            <div class="station-item {failed_class}">
                <div class="station-header">
                    <div class="station-name">{name}</div>
                    <div class="station-stats">
                        <span class="pass-count">âœ“ {passed}</span>
                        <span class="fail-count">âœ— {failed}</span>
                        <span>Total: {total}</span>
                    </div>
                </div>
            </div>
            """

        html += '</div></div>'
        return html

    def _generate_human_review_section(self, review_items: List[Dict]) -> str:
        """Generate human review section"""
        if not review_items:
            return '<div class="section"><h2>ðŸ‘¤ Human Review Queue</h2><p>âœ“ No items require human review!</p></div>'

        html = f'<div class="section"><h2>ðŸ‘¤ Human Review Queue ({len(review_items)} items)</h2>'

        for item in review_items:
            html += f"""
            <div class="review-item">
                <h4>{item['station']} - {item['test']}</h4>
                <p><strong>Error:</strong> {item['error']}</p>
                <p><strong>Severity:</strong> {item['severity']}</p>
            </div>
            """

        html += '</div>'
        return html

    def _generate_performance_details(self) -> str:
        """Generate performance details section"""
        return """
        <div class="section">
            <h2>âš¡ Performance Summary</h2>
            <p>Detailed performance metrics available in test results JSON files.</p>
            <p>VR Target: 90+ FPS | Memory Target: < 4GB</p>
        </div>
        """

    def _generate_javascript(self, trends: Dict) -> str:
        """Generate JavaScript for charts"""
        return f"""
        // Pass Rate Chart
        new Chart(document.getElementById('passRateChart'), {{
            type: 'line',
            data: {{
                labels: {json.dumps(trends.get('timestamps', [])[-15:])},
                datasets: [{{
                    label: 'Pass Rate (%)',
                    data: {json.dumps(trends.get('pass_rates', [])[-15:])},
                    borderColor: '#4caf50',
                    backgroundColor: 'rgba(76, 175, 80, 0.1)',
                    tension: 0.4
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: false,
                plugins: {{
                    legend: {{ labels: {{ color: '#e0e0e0' }} }},
                    title: {{ display: true, text: 'Pass Rate Trend', color: '#e0e0e0' }}
                }},
                scales: {{
                    y: {{ beginAtZero: true, max: 100, ticks: {{ color: '#999' }} }},
                    x: {{ ticks: {{ color: '#999' }} }}
                }}
            }}
        }});

        // FPS Chart
        new Chart(document.getElementById('fpsChart'), {{
            type: 'line',
            data: {{
                labels: {json.dumps(trends.get('timestamps', [])[-15:])},
                datasets: [{{
                    label: 'Average FPS',
                    data: {json.dumps(trends.get('fps_values', [])[-15:])},
                    borderColor: '#667eea',
                    backgroundColor: 'rgba(102, 126, 234, 0.1)',
                    tension: 0.4
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: false,
                plugins: {{
                    legend: {{ labels: {{ color: '#e0e0e0' }} }},
                    title: {{ display: true, text: 'FPS Trend', color: '#e0e0e0' }}
                }},
                scales: {{
                    y: {{ beginAtZero: true, ticks: {{ color: '#999' }} }},
                    x: {{ ticks: {{ color: '#999' }} }}
                }}
            }}
        }});

        // Memory Chart
        new Chart(document.getElementById('memoryChart'), {{
            type: 'line',
            data: {{
                labels: {json.dumps(trends.get('timestamps', [])[-15:])},
                datasets: [{{
                    label: 'Memory Usage (MB)',
                    data: {json.dumps(trends.get('memory_values', [])[-15:])},
                    borderColor: '#ff9800',
                    backgroundColor: 'rgba(255, 152, 0, 0.1)',
                    tension: 0.4
                }}]
            }},
            options: {{
                responsive: true,
                maintainAspectRatio: false,
                plugins: {{
                    legend: {{ labels: {{ color: '#e0e0e0' }} }},
                    title: {{ display: true, text: 'Memory Usage Trend', color: '#e0e0e0' }}
                }},
                scales: {{
                    y: {{ beginAtZero: true, ticks: {{ color: '#999' }} }},
                    x: {{ ticks: {{ color: '#999' }} }}
                }}
            }}
        }});
        """

    def _get_status_class(self, value: float, good_threshold: float, warning_threshold: float) -> str:
        """Get status class based on thresholds"""
        if value >= good_threshold:
            return 'pass'
        elif value >= warning_threshold:
            return 'warning'
        return 'fail'

    def _get_fps_status(self, fps: float) -> str:
        """Get FPS status class"""
        if fps >= 90:
            return 'pass'
        elif fps >= 60:
            return 'warning'
        return 'fail'

    def _get_memory_status(self, memory_mb: float) -> str:
        """Get memory status class"""
        if memory_mb < 3072:  # < 3GB
            return 'pass'
        elif memory_mb < 4096:  # < 4GB
            return 'warning'
        return 'fail'


def main():
    parser = argparse.ArgumentParser(description='Generate test dashboard')
    parser.add_argument('--input', required=True, help='Test results directory')
    parser.add_argument('--output', default='test_dashboard.html', help='Output HTML file')
    parser.add_argument('--auto-refresh', type=int, default=0,
                       help='Auto-refresh interval in seconds (0 = disabled)')

    args = parser.parse_args()

    generator = DashboardGenerator(Path(args.input))
    generator.generate_html(Path(args.output), args.auto_refresh)


if __name__ == "__main__":
    main()
